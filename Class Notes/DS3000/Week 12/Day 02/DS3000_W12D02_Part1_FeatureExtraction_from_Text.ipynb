{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"res/ds3000.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Week 12 - Day 1</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Part 4: Feature Extraction from Text</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Outline\n",
    "1. <a href='#1'>CountVectorizer</a>\n",
    "2. <a href='#2'>TfidfVectorizer</a>\n",
    "3. <a href='#3'>Stop Words</a>\n",
    "4. <a href='#4'>min_df</a>\n",
    "5. <a href='#5'>ngrams</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "quotes = pd.read_csv(\"res/quotes.csv\", header=None)\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(quotes[0].values)\n",
    "bag_of_words = vect.transform(quotes[0].values)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "quote_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "quote_df[\"quote\"] = quotes[0].values\n",
    "quote_df.set_index(\"quote\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TfidfVectorizer\n",
    "* Converts a collection of raw documents to a matrix of TF-IDF features.\n",
    "* Allows us to weight words based on how important they are to a string\n",
    "\n",
    "\n",
    "* High weight is given to words, or terms, that appear often in a particular string, but don't appear often in the corpus (across all strings)\n",
    "    * Features with low tf-idf are either commonly used across all strings or rarely used and only occur in long strings\n",
    "    \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer().fit(quotes[0].values)\n",
    "\n",
    "print(\"Number of features: \", #TODO in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the words in the quotes based on the vocabulary built using tfidf\n",
    "bag_of_words = #TODO in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "quote_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "quote_df[\"quote\"] = quotes[0].values\n",
    "quote_df.set_index(\"quote\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stop words\n",
    "* It is common practice to remove stop words (such as \"the\", \"this\", and \"in\") from text before vectorizing strings\n",
    "    * Need a list of stop words\n",
    "* Both CountVectorizer and TfidfVectorizer can do this\n",
    "    * Use the stop_words keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of stop words: \", len(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = list(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(#TODO in class).fit(quotes[0].values)\n",
    "\n",
    "print(\"Number of features: \", len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names()[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. min_df\n",
    "* Allows us to specify the minimum number of different documents in which the word should appear \n",
    "* cut-off value used when constructing the bag of words\n",
    "* If a word appears in one document only, it has little to contribute to the model\n",
    "    * so no need to include in the vocabulary (and thus in the bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#set the minimum of documents in which the word should appear before it can be included in the vocabulary\n",
    "vect = TfidfVectorizer(#TODO in class).fit(quotes[0].values)\n",
    "\n",
    "bag_of_words = vect.transform(quotes[0].values)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: \", len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "quote_df[\"quote\"] = quotes[0].values\n",
    "quote_df.set_index(\"quote\", inplace=True)\n",
    "\n",
    "quote_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ngrams\n",
    "* Allows us to count pairs or triplets tokens that appear next to each other\n",
    "* ngram_range = (1,2) \n",
    "    * creates unigrams and bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#set the minimum of documents in which the word should appear before it can be included in the vocabulary\n",
    "vect = TfidfVectorizer(#TODO in class).fit(quotes[0].values)\n",
    "\n",
    "bag_of_words = vect.transform(quotes[0].values)\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: \", len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names[::12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
