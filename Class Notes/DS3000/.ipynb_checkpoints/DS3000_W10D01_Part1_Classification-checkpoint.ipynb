{
  "cells": [
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "<center> <img src=\"res/ds3000.png\"> </center>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<center> <h1> Week 10 - Day 1 </h1> </center>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<center> <h2> Part 1: Supervised Machine Learning: Classification </h2></center>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "## Outline\n1. <a href='#1'>Scikit-Learn</a>\n2. <a href='#2'>Preparing the Data for Use with Scikit-Learn</a>\n3. <a href='#3'>Splitting the Data for Training and Testing</a>\n4. <a href='#4'>Creating the Model</a>\n5. <a href='#5'>Training the Model</a>\n6. <a href='#6'>Predicting Classes</a>\n7. <a href='#7'>Prediction Accuracy</a>\n8. <a href='#8'>Summary: k-NN Classification</a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"1\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 1. Scikit-Learn \n* Scikit-learn, also called **sklearn**, conveniently packages the most effective machine-learning algorithms as **estimators**. \n* **Each is encapsulated, so you don’t see the intricate details and heavy mathematics of how these algorithms work.**\n* You’ll use **scikit-learn** to **train each model** on a subset of your data, then **test each model** on the rest to see how well your model works. \n* Once your models are trained, you’ll put them to work making **predictions** based on **data they have not seen**. \n* https://scikit-learn.org/stable/"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 1.2. k-Nearest Neighbors Algorithm (k-NN) \n* Predict a sample’s class by looking at the **_k_ training samples** **nearest in \"distance\"** to the **sample** \n* Filled dots represent four distinct classes—A (blue), B (green), C (red) and D (purple) \n* **Class with the most “votes” wins**\n    * **Odd _k_ value** **avoids ties** &mdash; there’s never an equal number of votes\n    \n<img src=\"res/nearest.png\" alt=\"Diagram for the discussion of the k-nearest neighbors algorithm\" width=300/>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"2\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 2. Preparing the Data for Use with Scikit-Learn\n* Scikit-learn estimators require samples to be stored in a **two-dimensional array of floating-point values** (or **list of lists** or **pandas `DataFrame`**): \n\t* Each **row** represents one **sample** \n\t* Each **column** in a given row represents one **feature** for that sample\n* For **categorical features** (e.g., **strings** like `'spam'` or `'not-spam'`), you’d have to **preprocess** those features into **numerical values**—known as **one-hot encoding**"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.read_csv(\"res/fruits_data.csv\")\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "df[\"fruit\"].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "#define a fruit dictionary with fruit names and numeric values\nfruits_dict = {1: \"apple\", 2: \"orange\", 3: \"pear\", 4: \"clementine\", 5: \"banana\", 6: \"fig\", 7:\"lemon\"}\nfruits_dict",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "fruits_nominal = {\"apple\":1, \"orange\":2, \"pear\":3, \"clementine\": 4, \"banana\":5, \"fig\": 6, \"lemon\": 7}\nfruits_nominal",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Add a new column to hold numeric values for fruit names (sklearn requires this)"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def transform_fruit_name(column):\n    return fruits_nominal[column]\n\ndf[\"target\"] = df[\"fruit\"].apply(transform_fruit_name)\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 2.1. Visualizing the Dataset"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import plotly.express as px\nfig = px.scatter_matrix(data, dimensions = [\"weight\", \"width\", \"height\"], color = \"fruit\")\nfig.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 2.2. Retrieving Features and Target Columns"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "features = df[[\"weight\", \"width\", \"height\"]]\nfeatures.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "target = df[\"target\"]\ntarget.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"3\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 3. Splitting the Data for Training and Testing\n* Typically train a model with a subset of a dataset\n* Save a portion for testing, so you can evaluate a model’s performance using unseen data\n* Function **`train_test_split`** shuffles the data to randomize it, then splits the samples in the `data` array and the target values in the `target` array into training and testing sets\n    * Shuffling helps ensure that the training and testing sets have similar characteristics"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 3.1. train_test_split() Function\n* Returns a **tuple of four elements** in which the **first two** are the **samples** split into **training** and **testing sets**, and the **last two** are the **corresponding target values** split into **training** and **testing sets**\n* Convention: \n    * **Uppercase `X`** represents **samples**\n    * **Lowercase `y`** represents **target values**\n* random_state allows us to specify a random seed for reproducibility\n* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 3.2. Training and Testing Set Sizes \n* **By default**, `train_test_split` reserves **75%** of the data for **training** and **25%** for **testing**\n* Can specify the ratio using **train_size** or **test_size** keyword\n    * train_size = .80 (80% for training and 20% for testing)\n    "
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"4\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 4. Creating the Model \n* In **scikit-learn**, **models** are called **estimators** \n* Once the dataset is split into training and testing sets, we can create a model that utilizes a ML algorithm to learn from the data, which then can be used to make predictions and classify new samples\n* **`KNeighborsClassifier`** estimator implements the **k-nearest neighbors algorithm**"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"5\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 5. Training the Model\n* Can train the model with the `KNeighborsClassifier` object’s **`fit` method**\n* Involves loading **sample training set (`X_train`)** and **target training set (`y_train`)** into the estimator"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "knn.fit(X=X_train, y=y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* By default, **KNeighborsClassifier** uses n_neighbors=5\n    * 5-nearest neighbors\n    * Can change it specifying the keyword in method call"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        }
      },
      "cell_type": "markdown",
      "source": "* **`KNeighborsClassifier`’s `fit` method** **just loads the data** \n    * **No initial learning process** \n    * The **estimator** is **lazy** &mdash; work is performed only when you use it to make predictions"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"6\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 6. Predicting Classes\n* Can make predictions using the `KNeighborsClassifier`’s  **`predict` method**\n* Returns an array containing the **predicted class of each test image**: "
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "predicted = knn.predict(X=X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "expected = y_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "results = pd.DataFrame(predicted, columns = [\"Predicted\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "results[\"Expected\"] = expected.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "results",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Locate all incorrect predictions for the entire test set:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "results = results[results[\"Predicted\"]!=results[\"Expected\"]]\nresults",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "len(results)/len(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* Incorrectly predicted only ? of the ? test samples"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 6.1. Predicting a Single Fruit's Name"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "fruit_prediction = knn.predict([[4.3,6.2,7.2]])\nfruits_dict[fruit_prediction[0]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"7\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 7. Prediction Accuracy\nEstimator Method `score`\n* Returns an **indication of how well the estimator performs** on **test data** \n* For **classification estimators**, returns the **prediction accuracy** for the test data:"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "accuracy = knn.score(X_test, y_test)\naccuracy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "accuracy*100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "cell_type": "markdown",
      "source": "* kNeighborsClassifier with default k of 5 achieved this prediction accuracy using only the estimator’s default parameters\n    * Can use hyperparameter tuning to try to determine the optimal value for k"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"8\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 8. Summary: k-NN Classification"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n\nknn = KNeighborsClassifier()\n\nknn.fit(X=X_train, y=y_train)\n\npredicted = knn.predict(X=X_test)\n\nexpected = y_test\n\naccuracy = knn.score(X_test, y_test)\naccuracy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}