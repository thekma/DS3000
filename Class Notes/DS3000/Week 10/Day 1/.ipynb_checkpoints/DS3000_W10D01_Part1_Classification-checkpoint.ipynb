{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <img src=\"res/ds3000.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Week 10 - Day 1 </h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Part 1: Supervised Machine Learning: Classification </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Outline\n",
    "1. <a href='#1'>Scikit-Learn</a>\n",
    "2. <a href='#2'>Preparing the Data for Use with Scikit-Learn</a>\n",
    "3. <a href='#3'>Splitting the Data for Training and Testing</a>\n",
    "4. <a href='#4'>Creating the Model</a>\n",
    "5. <a href='#5'>Training the Model</a>\n",
    "6. <a href='#6'>Predicting Classes</a>\n",
    "7. <a href='#7'>Prediction Accuracy</a>\n",
    "8. <a href='#8'>Summary: k-NN Classification</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Scikit-Learn \n",
    "* Scikit-learn, also called **sklearn**, conveniently packages the most effective machine-learning algorithms as **estimators**. \n",
    "* **Each is encapsulated, so you don’t see the intricate details and heavy mathematics of how these algorithms work.**\n",
    "* You’ll use **scikit-learn** to **train each model** on a subset of your data, then **test each model** on the rest to see how well your model works. \n",
    "* Once your models are trained, you’ll put them to work making **predictions** based on **data they have not seen**. \n",
    "* https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2. k-Nearest Neighbors Algorithm (k-NN) \n",
    "* Predict a sample’s class by looking at the **_k_ training samples** **nearest in \"distance\"** to the **sample** \n",
    "* Filled dots represent four distinct classes—A (blue), B (green), C (red) and D (purple) \n",
    "* **Class with the most “votes” wins**\n",
    "    * **Odd _k_ value** **avoids ties** &mdash; there’s never an equal number of votes\n",
    "    \n",
    "<img src=\"res/nearest.png\" alt=\"Diagram for the discussion of the k-nearest neighbors algorithm\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Preparing the Data for Use with Scikit-Learn\n",
    "* Scikit-learn estimators require samples to be stored in a **two-dimensional array of floating-point values** (or **list of lists** or **pandas `DataFrame`**): \n",
    "\t* Each **row** represents one **sample** \n",
    "\t* Each **column** in a given row represents one **feature** for that sample\n",
    "* For **categorical features** (e.g., **strings** like `'spam'` or `'not-spam'`), you’d have to **preprocess** those features into **numerical values**—known as **one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"res/fruits_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"fruit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#define a fruit dictionary with fruit names and numeric values\n",
    "fruits_dict = {1: \"apple\", 2: \"orange\", 3: \"pear\", 4: \"clementine\", 5: \"banana\", 6: \"fig\", 7:\"lemon\"}\n",
    "fruits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_nominal = {\"apple\":1, \"orange\":2, \"pear\":3, \"clementine\": 4, \"banana\":5, \"fig\": 6, \"lemon\": 7}\n",
    "fruits_nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Add a new column to hold numeric values for fruit names (sklearn requires this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fruit_name(column):\n",
    "    return fruits_nominal[column]\n",
    "\n",
    "df[\"target\"] = df[\"fruit\"].apply(transform_fruit_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1. Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_matrix(data, dimensions = [\"weight\", \"width\", \"height\"], color = \"fruit\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2. Retrieving Features and Target Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = df[[\"weight\", \"width\", \"height\"]]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "target = df[\"target\"]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Splitting the Data for Training and Testing\n",
    "* Typically train a model with a subset of a dataset\n",
    "* Save a portion for testing, so you can evaluate a model’s performance using unseen data\n",
    "* Function **`train_test_split`** shuffles the data to randomize it, then splits the samples in the `data` array and the target values in the `target` array into training and testing sets\n",
    "    * Shuffling helps ensure that the training and testing sets have similar characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1. train_test_split() Function\n",
    "* Returns a **tuple of four elements** in which the **first two** are the **samples** split into **training** and **testing sets**, and the **last two** are the **corresponding target values** split into **training** and **testing sets**\n",
    "* Convention: \n",
    "    * **Uppercase `X`** represents **samples**\n",
    "    * **Lowercase `y`** represents **target values**\n",
    "* random_state allows us to specify a random seed for reproducibility\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2. Training and Testing Set Sizes \n",
    "* **By default**, `train_test_split` reserves **75%** of the data for **training** and **25%** for **testing**\n",
    "* Can specify the ratio using **train_size** or **test_size** keyword\n",
    "    * train_size = .80 (80% for training and 20% for testing)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Creating the Model \n",
    "* In **scikit-learn**, **models** are called **estimators** \n",
    "* Once the dataset is split into training and testing sets, we can create a model that utilizes a ML algorithm to learn from the data, which then can be used to make predictions and classify new samples\n",
    "* **`KNeighborsClassifier`** estimator implements the **k-nearest neighbors algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Training the Model\n",
    "* Can train the model with the `KNeighborsClassifier` object’s **`fit` method**\n",
    "* Involves loading **sample training set (`X_train`)** and **target training set (`y_train`)** into the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* By default, **KNeighborsClassifier** uses n_neighbors=5\n",
    "    * 5-nearest neighbors\n",
    "    * Can change it specifying the keyword in method call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **`KNeighborsClassifier`’s `fit` method** **just loads the data** \n",
    "    * **No initial learning process** \n",
    "    * The **estimator** is **lazy** &mdash; work is performed only when you use it to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Predicting Classes\n",
    "* Can make predictions using the `KNeighborsClassifier`’s  **`predict` method**\n",
    "* Returns an array containing the **predicted class of each test image**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "predicted = knn.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(predicted, columns = [\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Expected\"] = expected.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Locate all incorrect predictions for the entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[results[\"Predicted\"]!=results[\"Expected\"]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)/len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Incorrectly predicted only ? of the ? test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6.1. Predicting a Single Fruit's Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_prediction = knn.predict([[4.3,6.2,7.2]])\n",
    "fruits_dict[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7. Prediction Accuracy\n",
    "Estimator Method `score`\n",
    "* Returns an **indication of how well the estimator performs** on **test data** \n",
    "* For **classification estimators**, returns the **prediction accuracy** for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = knn.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* kNeighborsClassifier with default k of 5 achieved this prediction accuracy using only the estimator’s default parameters\n",
    "    * Can use hyperparameter tuning to try to determine the optimal value for k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8. Summary: k-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X=X_train, y=y_train)\n",
    "\n",
    "predicted = knn.predict(X=X_test)\n",
    "\n",
    "expected = y_test\n",
    "\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
