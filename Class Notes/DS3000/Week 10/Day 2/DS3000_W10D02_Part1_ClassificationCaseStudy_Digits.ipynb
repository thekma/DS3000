{
  "cells": [
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "<center> <img src=\"res/ds3000.png\"> </center>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<center> <h1> Week 10 - Day 2 </h1> </center>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<center> <h2> Part 1: Classification Case Study </h2></center>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "## Outline\n1. <a href='#1'>ScikitLearn's Digits Dataset</a>\n2. <a href='#2'>Loading the Dataset with the load_digits Function</a>\n3. <a href='#3'>Data Preparation</a>\n4. <a href='#4'>Classifying Digits</a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"1\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 1. Classification Case Study: Digits Dataset\n[**Digits dataset**](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) bundled with scikit-learn\n* 8-by-8 pixel images representing 1797 hand-written digits (0 through 9) \n* Classification Goal: **Predict** which digit an image represents"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "<center><img src = \"res/digits0-9.png\" width=400/></center>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 1.1. [Datasets Bundled with Scikit-Learn](http://scikit-learn.org/stable/datasets/index.html)\n* Scikit-learn package up popular datasets for you to experiment with\n* Scikit-learn also provides capabilities for loading datasets from other sources, such as the 20,000+ datasets available at https://openml.org. \n\n| Datasets bundled with scikit-learn | &nbsp;\n| :--- | :---\n| **_\"Toy\" datasets_** | **_Real-world datasets_**\n| Boston house prices | Olivetti faces\n| Iris plants | 20 newsgroups text\n| Diabetes | Labeled Faces in the Wild face recognition\n| Optical recognition of handwritten digits | Forest cover types\n| Linnerrud | RCV1\n| Wine recognition | Kddcup 99 \n| Breast cancer Wisconsin (diagnostic) | California Housing "
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"2\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 2.  Loading the Dataset with the **`load_digits` Function** \n* Returns a **`Bunch`** object containing **digit samples** and **metadata**\n* A **`Bunch`** is a dictionary with additional **dataset-specific attributes**"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.datasets import load_digits",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits = load_digits()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 2.1. Displaying Digits Dataset's Description\n* **Digits dataset** is a subset of the [**UCI (University of California Irvine) ML hand-written digits dataset**](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)\n    * Original dataset: **5620 samples**—3823 for **training** and 1797 for **testing** \n    * **Digits dataset**: Only the **1797 testing samples**\n* A Bunch’s **`DESCR` attribute** contains dataset's description \n    * Each sample has **`64` features** (**`Number of Attributes`**) that represent an **8-by-8 image** with **pixel values `0`–`16`** (**`Attribute Information`**)\n    * **No missing values** (**`Missing Attribute Values`**) \n* **64 features** may seem like a lot\n    * Datasets can have **hundreds**, **thousands** or even **millions of features**\n    * Processing datasets like these can require enormous computing capabilities"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(digits.DESCR)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 2.2. Checking the Sample and Target Sizes\n* `Bunch` object’s **`data`** and **`target`** attributes are **NumPy arrays**:\n* **`data` array**: The **1797 samples** (digit images), each with **64 features** with values**&nbsp;0** (white) to **16** (black), representing **pixel intensities**\n    ![Pixel intensities in grayscale shades from white (0) to black (16)](res/grays.png \"Pixel intensities in grayscale shades from white (0) to black (16)\")\n\n\n* **`target` array**: The **images’ labels**, (classes) indicating **which digit** each image represents"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.target",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Confirm number of **samples** and **features** (per sample) via `data` array’s **`shape`**"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Confirm that **number of target values matches number of samples** via `target` array’s `shape`\n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.target.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### 2.3. A Sample Digit Image \n* Images are **two-dimensional**—width and a height in pixels \n* Digits dataset's `Bunch` object has an **`images` attribute**\n    * Each element is an **8-by-8 array** representing a **digit image’s pixel intensities**\n* Scikit-learn stores the intensity values as **NumPy type `float64`**"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.images[13]  # show array for sample image at index 13",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Visualization of `digits.images[13]`\n\n    <img src=\"res/sampledigit3.png\" alt=\"Image of a handwritten digit 3\" width=\"300px\"/>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.target[13]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"3\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "## 3. Data Preparation\n* Better to store the datasets in a DataFrame"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.DataFrame(digits.data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df[\"target\"] = digits.target",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.iloc[13, 0:64].values.reshape(8,8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "* Let's define our features and target variables"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        },
        "trusted": false
      },
      "cell_type": "code",
      "source": "features = df.drop(\"target\", axis = 1)\nfeatures.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "target = df[\"target\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "<a id=\"4\"></a>"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 4. Classifying Digits using K-Nearest Neighbors \n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n\n#select a classifier\nknn = KNeighborsClassifier()\n\n#create the model by fitting the training data\nknn.fit(X=X_train, y=y_train)\n\n#make predictions on the test set\npredicted = knn.predict(X=X_test)\n\nexpected = y_test\n\n#prediction accuracy\naccuracy = knn.score(X_test, y_test)\nprint(\"Prediction accuracy on the test data:\", format(accuracy*100, \".2f\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "cell_type": "markdown",
      "source": "* Predicting the digit label for a single item"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.data[13]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "digits.target[13]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "predict_digit = knn.predict(digits.data[13].reshape(1, -1))\nprint(\"The digit is \", predict_digit[0])",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}